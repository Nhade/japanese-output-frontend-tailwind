import sqlite3
import json
import os
from datetime import datetime
from ai_service import BASE_URL, API_KEY, MODEL_NAME, AI_TIMEOUT
import requests

def call_llm(messages):
    url = f"{BASE_URL}/api/chat"
    headers = {
        "Authorization": f"Bearer {API_KEY}",
        "Content-Type": "application/json"
    }
    payload = {
        "model": MODEL_NAME,
        "messages": messages,
        "stream": False,
        "temperature": 0.7 
    }
    try:
        response = requests.post(url, json=payload, headers=headers, timeout=AI_TIMEOUT)
        response.raise_for_status()
        
        data = response.json()
        content = data.get("message", {}).get("content", "")
        if not content:
             content = data.get("response", "")
        return content
    except Exception as e:
        print(f"LLM Call Error: {e}")
        return None

def generate_daily_review_agent(user_id, db_path):
    conn = sqlite3.connect(db_path)
    conn.row_factory = sqlite3.Row
    
    # 1. Retrieve today's mistakes (using localtime to ensure local time today)
    query = '''
        SELECT e.question_sentence, e.correct_answer, al.user_answer, al.error_type
        FROM answer_log al
        JOIN exercise e ON al.exercise_id = e.exercise_id
        WHERE al.user_id = ? 
          AND al.is_correct = 0 
          AND date(al.answered_timestamp) = date('now', 'localtime')
    '''

    print(f"Querying mistakes for user {user_id} on {datetime.now().date()}")
    
    mistakes = conn.execute(query, (user_id,)).fetchall()
    conn.close()

    if not mistakes:
        return "ä»Šå¤©é‚„æ²’æœ‰éŒ¯é¡Œç´€éŒ„å–”ï¼å»ç·´ç¿’å¹¾é¡Œå†ä¾†å§ï¼ğŸ’ª"

    # Format mistake data for AI
    mistake_text = ""
    for idx, m in enumerate(mistakes, 1):
        mistake_text += f"{idx}. Q: {m['question_sentence']}\n   User: {m['user_answer']} | Correct: {m['correct_answer']} | Type: {m['error_type']}\n"

    # --- Agent Step 1: Analyze patterns (Analysis) ---
    print("Agent Step 1: Analyzing patterns...")
    prompt_analysis = f"""
    ä½ æ˜¯æ—¥æ–‡æ•™å­¸å°ˆå®¶ã€‚è«‹åˆ†æä»¥ä¸‹å­¸ç”Ÿçš„ä»Šæ—¥éŒ¯é¡Œï¼Œæ‰¾å‡º 2-3 å€‹ä¸»è¦çš„å¼±é»æ¨¡å¼ï¼ˆä¾‹å¦‚ï¼šç‰¹å®šåŠ©è©ææ··ã€å‹•è©è®ŠåŒ–ä¸ç†Ÿã€é‚„æ˜¯å–®ç´”ç²—å¿ƒï¼Ÿï¼‰ã€‚
    
    éŒ¯é¡Œåˆ—è¡¨ï¼š
    {mistake_text}
    
    è«‹ç°¡çŸ­åˆ—å‡ºåˆ†æçµæœã€‚
    """
    analysis_result = call_llm([{"role": "user", "content": prompt_analysis}])

    # --- Agent Step 2: Draft review (Drafting) ---
    print("Agent Step 2: Drafting review...")
    prompt_draft = f"""
    åŸºæ–¼ä¸Šè¿°çš„åˆ†æçµæœï¼Œè«‹ç”¨ã€Œæº«æš–ã€é¼“å‹µä½†å°ˆæ¥­ã€çš„èªæ°£ï¼Œå¯«ä¸€ä»½ã€Œä»Šæ—¥å­¸ç¿’ç¸½çµã€ã€‚
    
    åˆ†æçµæœï¼š
    {analysis_result}
    
    è¦æ±‚ï¼š
    1. æŒ‡å‡ºä»Šå¤©åšå¾—å¥½çš„åœ°æ–¹ï¼ˆå³ä½¿æ˜¯éŒ¯é¡Œï¼Œä¹Ÿè¦è‚¯å®šå˜—è©¦ï¼‰ã€‚
    2. é‡é»è¬›è§£ 1-2 å€‹ä»Šå¤©æœ€éœ€è¦æ”¹é€²çš„è§€å¿µã€‚
    3. çµ¦å‡ºä¸€å€‹å…·é«”çš„å»ºè­°ç·´ç¿’æ–¹å‘ã€‚
    4. ä½¿ç”¨ç¹é«”ä¸­æ–‡ã€‚
    """

    messages_draft = [
        {"role": "user", "content": prompt_analysis},
        {"role": "assistant", "content": analysis_result},
        {"role": "user", "content": prompt_draft}
    ]
    draft_result = call_llm(messages_draft)

    # --- Agent Step 3: Final polishing (Polishing) ---
    print("Agent Step 3: Polishing...")
    prompt_polish = f"""
    è«‹ä½œç‚ºç·¨è¼¯ï¼Œæª¢æŸ¥ä¸Šè¿°è‰ç¨¿ã€‚
    å„ªåŒ–æ’ç‰ˆï¼Œä½¿ç”¨ Markdown æ ¼å¼ï¼ˆBold, List, Quoteï¼‰ã€‚
    ç¢ºä¿èªæ°£åƒæ˜¯ä¸€å€‹è²¼å¿ƒçš„ AI åŠ©æ•™ (Agent)ã€‚
    é–‹é ­åŠ ä¸Šã€ŒğŸ“… ä»Šæ—¥éŒ¯é¡Œå›é¡§ã€ã€‚
    """
    messages_polish = messages_draft + [
        {"role": "assistant", "content": draft_result},
        {"role": "user", "content": prompt_polish}
    ]
    final_result = call_llm(messages_polish)

    return final_result
